
Train [0 / 12584]       loss: 1.3913354873657227
C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Train [1280 / 12584]       loss: 1.1616756916046143
Train [2560 / 12584]       loss: 0.7980432510375977
Train [3840 / 12584]       loss: 0.7376025915145874
Train [5120 / 12584]       loss: 0.7322168946266174
Traceback (most recent call last):
  File "c:\Users\QbaSo\Desktop\praca magisterska\myCode\samllNetCL TaskIL Noise Rehersal.py", line 105, in <module>
    train_losses, tasks_losses, exemplers = train_validation_all_classes(model, optimizer, tasks, rehersal_loader, epoch=1, log_interval = 10)
  File "c:\Users\QbaSo\Desktop\praca magisterska\myCode\samllNetCL TaskIL Noise Rehersal.py", line 38, in train_validation_all_classes
    curr_task_acc = test(model, tasks[i], i, print_accuracy=False)
  File "c:\Users\QbaSo\Desktop\praca magisterska\myCode\samllNetCL TaskIL Noise Rehersal.py", line 54, in test
    for data, target in test_loader:
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\dataloader.py", line 628, in __next__
    data = self._next_data()
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\_utils\fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\utils\data\_utils\fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\datasets\mnist.py", line 145, in __getitem__
    img = self.transform(img)
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\transforms\transforms.py", line 270, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\transforms\functional.py", line 360, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
  File "C:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torchvision\transforms\functional_tensor.py", line 934, in normalize
    if (std == 0).any():
KeyboardInterrupt