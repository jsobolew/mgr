
-------------------------------------------------- benchmark normal training --------------------------------------------------
Train [0 / 12665]       loss: 1.4194846153259277
c:\Users\QbaSo\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Train [1280 / 12665]       loss: 0.7523083090782166
Train [2560 / 12665]       loss: 0.7374029159545898
Train [3840 / 12665]       loss: 0.7116127610206604
Train [5120 / 12665]       loss: 0.7264640927314758
Train [6400 / 12665]       loss: 0.7067463994026184
Train [7680 / 12665]       loss: 0.701772153377533
Train [8960 / 12665]       loss: 0.7458817362785339
Train [10240 / 12665]       loss: 0.6923138499259949
Train [11520 / 12665]       loss: 0.6982681751251221
Train [0 / 12089]       loss: 1.4416568279266357
Train [1280 / 12089]       loss: 1.0628390312194824
Train [2560 / 12089]       loss: 0.8886224627494812
Train [3840 / 12089]       loss: 0.788657546043396
Train [5120 / 12089]       loss: 0.8201118111610413
Train [6400 / 12089]       loss: 0.7784382104873657
Train [7680 / 12089]       loss: 0.733189046382904
Train [8960 / 12089]       loss: 0.7310559749603271
Train [10240 / 12089]       loss: 0.7443845868110657
Train [11520 / 12089]       loss: 0.7532748579978943
Train [0 / 11263]       loss: 1.3986282348632812
Train [1280 / 11263]       loss: 0.8177869915962219
Train [2560 / 11263]       loss: 0.7439201474189758
Train [3840 / 11263]       loss: 0.7629224061965942
Train [5120 / 11263]       loss: 0.7152799963951111
Train [6400 / 11263]       loss: 0.707638144493103
Train [7680 / 11263]       loss: 0.7034275531768799
Train [8960 / 11263]       loss: 0.699175238609314
Train [10240 / 11263]       loss: 0.710544764995575
Train [0 / 12183]       loss: 1.5810383558273315
Train [1280 / 12183]       loss: 0.7225965261459351
Train [2560 / 12183]       loss: 0.7272484302520752
Train [3840 / 12183]       loss: 0.7085753679275513
Train [5120 / 12183]       loss: 0.7030137777328491
Train [6400 / 12183]       loss: 0.7017439603805542
Train [7680 / 12183]       loss: 0.7020290493965149
Train [8960 / 12183]       loss: 0.7046656012535095
Train [10240 / 12183]       loss: 0.7243521809577942
Train [11520 / 12183]       loss: 0.7037560939788818
Train [0 / 11800]       loss: 1.361911416053772
Train [1280 / 11800]       loss: 0.9455636739730835
Train [2560 / 11800]       loss: 0.8160618543624878
Train [3840 / 11800]       loss: 0.8089771866798401
Train [5120 / 11800]       loss: 0.7479240894317627
Train [6400 / 11800]       loss: 0.7495617866516113
Train [7680 / 11800]       loss: 0.7307095527648926
Train [8960 / 11800]       loss: 0.7321286797523499
Train [10240 / 11800]       loss: 0.7117520570755005
Train [11520 / 11800]       loss: 0.7492114901542664
-------------------------------------------------- benchmark normal training --------------------------------------------------
Train [0 / 12665]       loss: 1.4118423461914062
Train [1280 / 12665]       loss: 0.7474769949913025
Train [2560 / 12665]       loss: 0.7117952704429626
Train [3840 / 12665]       loss: 0.7254354953765869
Train [5120 / 12665]       loss: 0.719735324382782
Train [6400 / 12665]       loss: 0.7014641761779785
Train [7680 / 12665]       loss: 0.7004137635231018
Train [8960 / 12665]       loss: 0.7113218903541565
Train [10240 / 12665]       loss: 0.7005888223648071
Train [11520 / 12665]       loss: 0.701747477054596
Train [0 / 12089]       loss: 1.3970036506652832
Train [1280 / 12089]       loss: 1.3635190725326538
Train [2560 / 12089]       loss: 1.0469142198562622
Train [3840 / 12089]       loss: 0.7675513029098511
Train [5120 / 12089]       loss: 0.7840065360069275
Train [6400 / 12089]       loss: 0.9026123285293579
Train [7680 / 12089]       loss: 0.7363709211349487
Train [8960 / 12089]       loss: 0.7216590642929077
Train [10240 / 12089]       loss: 0.7853051424026489
Train [11520 / 12089]       loss: 0.738309383392334
Train [0 / 11263]       loss: 1.5148578882217407
Train [1280 / 11263]       loss: 0.7997941970825195
Train [2560 / 11263]       loss: 0.7472562193870544
Train [3840 / 11263]       loss: 0.70918869972229
Train [5120 / 11263]       loss: 0.7088345289230347
Train [6400 / 11263]       loss: 0.7041541934013367
Train [7680 / 11263]       loss: 0.7149912118911743
Train [8960 / 11263]       loss: 0.7046031951904297
Train [10240 / 11263]       loss: 0.7117663025856018
Train [0 / 12183]       loss: 1.221376895904541
Train [1280 / 12183]       loss: 0.7345186471939087
Train [2560 / 12183]       loss: 0.6944224238395691
Train [3840 / 12183]       loss: 0.6960669755935669
Train [5120 / 12183]       loss: 0.7039175033569336
Train [6400 / 12183]       loss: 0.7038536667823792
Train [7680 / 12183]       loss: 0.6895434260368347
Train [8960 / 12183]       loss: 0.7013987898826599
Train [10240 / 12183]       loss: 0.6962524652481079
Train [11520 / 12183]       loss: 0.6996428370475769
Train [0 / 11800]       loss: 2.107194662094116
Train [1280 / 11800]       loss: 1.2585210800170898
Train [2560 / 11800]       loss: 1.2145743370056152
Train [3840 / 11800]       loss: 0.8828643560409546
Train [5120 / 11800]       loss: 0.7796354293823242
Train [6400 / 11800]       loss: 0.7524040341377258
Train [7680 / 11800]       loss: 0.7816945314407349
Train [8960 / 11800]       loss: 0.745376467704773
Train [10240 / 11800]       loss: 0.7334038615226746
Train [11520 / 11800]       loss: 0.7421931028366089