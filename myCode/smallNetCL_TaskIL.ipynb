{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Nets import NetTaskIL\n",
    "from taskIL import train_validation_all_classes\n",
    "from dataloaders.mnist import MNIST_for_classes_TaskIL\n",
    "from dataloaders.noise import dataloader_pretraining_gray\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_all_classes(model, optimizer, tasks, device, epoch=1, log_interval = 1000):\n",
    "    train_losses = []\n",
    "    tasks_acc = [[], [], [], [], []]\n",
    "    exemplers = []\n",
    "\n",
    "    for taskNo in range(len(tasks)):\n",
    "        for batch_idx, (data, target) in enumerate(tasks[taskNo]):\n",
    "            model.train()\n",
    "\n",
    "            # training on task\n",
    "            output = model(taskNo, data.to(device))\n",
    "            loss = F.cross_entropy(output, target.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f\"Train [{batch_idx * len(data)} / {len(tasks[taskNo].dataset)}]       loss: {loss.item()}\")\n",
    "                for i in range(len(tasks)):\n",
    "                    curr_task_acc = test(model, tasks[i], i, device, print_accuracy=False)\n",
    "                    tasks_acc[i].append(curr_task_acc)\n",
    "                    # wandb.log({f\"acc_task_{i}\": curr_task_acc})\n",
    "\n",
    "            train_losses.append(loss.cpu().item())\n",
    "            # wandb.log({\"loss\": loss.item()})\n",
    "            exemplars = tasks[taskNo].batch_size * batch_idx\n",
    "            exemplers.append(exemplars)\n",
    "            # wandb.log({\"exemplers\": exemplers})\n",
    "    return train_losses, tasks_acc, exemplers\n",
    "\n",
    "def test(model, test_loader, taskNo, device, print_accuracy=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(taskNo, data.to(device))\n",
    "            test_loss += F.cross_entropy(output, target.to(device), size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cpu()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if print_accuracy:\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(run=1):\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    classes = np.arange(10)\n",
    "    np.random.shuffle(classes)\n",
    "    classes = list(classes)\n",
    "\n",
    "    task1 = MNIST_for_classes_TaskIL(classes.pop(), classes.pop())\n",
    "    task2 = MNIST_for_classes_TaskIL(classes.pop(), classes.pop())\n",
    "    task3 = MNIST_for_classes_TaskIL(classes.pop(), classes.pop())\n",
    "    task4 = MNIST_for_classes_TaskIL(classes.pop(), classes.pop())\n",
    "    task5 = MNIST_for_classes_TaskIL(classes.pop(), classes.pop())\n",
    "\n",
    "    tasks = [task1 ,task2, task3, task4, task5]\n",
    "\n",
    "    # wandb.init(\n",
    "    #     # set the wandb project where this run will be logged\n",
    "    #     project=\"no rehersal small net MNIST Task IL\",\n",
    "        \n",
    "    #     # track hyperparameters and run metadata\n",
    "    #     config={\n",
    "    #     \"setup\": \"task IL\",\n",
    "    #     \"learning_rate\": 0.1,\n",
    "    #     \"architecture\": \"NetTaskIL\",\n",
    "    #     \"dataset\": \"MNIST\",\n",
    "    #     \"epochs\": 1,\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    model = NetTaskIL(10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    train_losses, tasks_losses, exemplers = train_validation_all_classes(model, optimizer, tasks, device, epoch=1, log_interval = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [0 / 11379]       loss: 0.7130669951438904\n",
      "Train [1280 / 11379]       loss: 0.5814456939697266\n",
      "Train [2560 / 11379]       loss: 0.15896332263946533\n",
      "Train [3840 / 11379]       loss: 0.15838977694511414\n",
      "Train [5120 / 11379]       loss: 0.10361383855342865\n",
      "Train [6400 / 11379]       loss: 0.10558898746967316\n",
      "Train [7680 / 11379]       loss: 0.06071097031235695\n",
      "Train [8960 / 11379]       loss: 0.08446119725704193\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\QbaSo\\Desktop\\praca magisterska\\myCode\\smallNetCL_TaskIL.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\QbaSo\\Desktop\\praca magisterska\\myCode\\smallNetCL_TaskIL.ipynb Cell 4\u001b[0m in \u001b[0;36mmain\u001b[1;34m(run)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model \u001b[39m=\u001b[39m NetTaskIL(\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m train_losses, tasks_losses, exemplers \u001b[39m=\u001b[39m train_validation_all_classes(model, optimizer, tasks, device, epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, log_interval \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\QbaSo\\Desktop\\praca magisterska\\myCode\\smallNetCL_TaskIL.ipynb Cell 4\u001b[0m in \u001b[0;36mtrain_validation_all_classes\u001b[1;34m(model, optimizer, tasks, device, epoch, log_interval)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain [\u001b[39m\u001b[39m{\u001b[39;00mbatch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(tasks[taskNo]\u001b[39m.\u001b[39mdataset)\u001b[39m}\u001b[39;00m\u001b[39m]       loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tasks)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     curr_task_acc \u001b[39m=\u001b[39m test(model, tasks[i], i, device, print_accuracy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     tasks_acc[i]\u001b[39m.\u001b[39mappend(curr_task_acc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# wandb.log({f\"acc_task_{i}\": curr_task_acc})\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\QbaSo\\Desktop\\praca magisterska\\myCode\\smallNetCL_TaskIL.ipynb Cell 4\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, test_loader, taskNo, device, print_accuracy)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         output \u001b[39m=\u001b[39m model(taskNo, data\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/QbaSo/Desktop/praca%20magisterska/myCode/smallNetCL_TaskIL.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target\u001b[39m.\u001b[39mto(device), size_average\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    263\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\functional.py:360\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\QbaSo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize\u001b[39m(tensor: Tensor, mean: List[\u001b[39mfloat\u001b[39m], std: List[\u001b[39mfloat\u001b[39m], inplace: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    918\u001b[0m     _assert_image_tensor(tensor)\n\u001b[1;32m--> 920\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tensor\u001b[39m.\u001b[39;49mis_floating_point():\n\u001b[0;32m    921\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput tensor should be a float tensor. Got \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    923\u001b[0m     \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mndim \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
